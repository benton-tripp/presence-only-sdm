---
title: 'SDM Benchmark Study Part 6: Re-Sampling Pseudo-Absence Points Using Iterative Sampling and BIOCLIM'
author: "Benton Tripp"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: flatly
    df_print: paged
  
---

```{r setup, include=F, warning=F, message=F}
knitr::opts_chunk$set(echo = T, message=F, warning=F, cache=F, root.dir="..")
```

## Setup

```{r setup-2, results='hide'}

library(sf)
library(terra)
library(ggplot2)
library(ggpubr)
library(dplyr)
library(readr)
library(data.table)
library(knitr)
library(purrr)
library(caret)
library(tidyr)

# Set seed for splitting
set.seed(19)

# Load dataset containing observation points, 
# but we can remove the "absence" points
df <- setDT(readRDS("artifacts/final_data/final_data.rds"))[
  observations > 0, .(common.name, state, lon, lat, geometry)]

# Define some global variables that will be referenced throughout the modeling 
states <- sort(unique(df$state))
species <- sort(unique(df$common.name))
spec.state <- expand.grid(species=species, 
                          state=states, 
                          stringsAsFactors=F)
                          
# Load Rasters
r.list <- states %>%
  set_names() %>%
  purrr::map(~rast(file.path("artifacts/final_rasters", 
                             paste0(.x, ".tif"))))

# Pre-processed rasters
# Define min/max scaling function for rasters
min.max.scale <- function(r, x=NULL, na.rm=T) {
  # If training data is provided
  if (!is.null(x)) {
    min.x <- min(x, na.rm=na.rm)
    max.x <- max(x, na.rm=na.rm)
    # Or just scale based on full raster values
  } else {
    min.x <- min(values(r), na.rm=na.rm)
    max.x <- max(values(r), na.rm=na.rm)
  }
  (r - min.x) / (max.x - min.x)
}

# Get model or other object from cache if it has been saved before
get.object <- function(obj, file.name, obj.path, 
                       read.func=readRDS, save.func=saveRDS, ...) {
  f.path <- file.path(obj.path, file.name)
  if (!dir.exists(obj.path)) {
    dir.create(obj.path)
  }
  # Object cache check
  if (file.exists(f.path)) {
    obj <- read.func(f.path)
  } else {
    save.func(obj, f.path, ...)
  }
  obj
}

# Get training/testing spatstat data, and 
# pre-process (scale) rasters 
r.list <- states %>%
  set_names() %>%
  purrr::map(function(st) {
    get.object(obj = {
      # Get raster
      r <- r.list[[st]]
      # Compute filtered & pre-processed rasters
      names(r) %>%
        set_names() %>%
        purrr::map(function(.x) {
          cat("Pre-processing", .x, "data in", st, "\n")
          r.layer <- r[[.x]]
          if (length(unique(values(r.layer))) > 2) {
            # Scale the data
            return(min.max.scale(r.layer))
          } else {
            return(r.layer)
          }
        }) %>%
        terra::rast()
    },
    file.name=paste0(st, ".tif"),
    obj.path="artifacts/preprocessed_rasters_updated",
    read.func=terra::rast,
    save.func=terra::writeRaster)
  })

```


## Updated Pseudo-Absence Selection Process

### Split into Training/Test Sets

As was done in Part 2 of the study, the data is split into a training set and a test set. The data is stratified based on latitude, longitude, species, and state to ensure that the distribution of these variables is consistent between the train and test sets. This stratification helps maintain representative samples and mitigates potential biases.

```{r train-test-split}

stratified.split.idx <- function(df, p=0.7, lat.lon.bins=25) {
  # Cut along lat/lon values to create grids (lat.bin & lon.bin)
  # lat.lon.bins is the number of divisions you want
  df$lat.bin <- cut(df$lat, breaks=lat.lon.bins, labels = F)
  df$lon.bin <- cut(df$lon, breaks=lat.lon.bins, labels = F)
  
  # Create a new variable combining the stratification variables
  df %>%
    # stratify on lat/lon bins, species, state
    mutate(strata = paste(lat.bin, lon.bin, common.name, state)) %>%
    pull(strata) %>%
    # Create the data partitions
    createDataPartition(., p = p, list = F) %>%
    suppressWarnings()
}

prepare.data <- function(df, p=.7, lat.lon.bins=25) {
  train.index <- stratified.split.idx(df, p=p, lat.lon.bins = lat.lon.bins)
  df.train <- df[train.index, ]
  df.test <- df[-train.index, ]
  
  list(train = df.train, 
       test = df.test,
       index = train.index)
}

# Get train/test indices
train.test <- prepare.data(df, .7)

# Split datatset
df.train <- df[train.test$index,] 
df.test <- df[-train.test$index,]

```

### BIOCLIM

```{r bioclim}
                         
bioclim.suitability <- function(sf.subset, r) {
  
  # Remove spatial layers (lat, lon, etc.)
  r <- r[[names(r)[!names(r) %in% 
                     c("lat", "lat.sqrd", "lon", 
                       "lon.lat.interaction", "lon.sqrd")]]]
  
  # Extract values from rasters at presence locations
  values.at.presences <- terra::extract(r, st_transform(sf.subset, crs=crs(r)))
  
  # Determine suitability masks based on unique values
  suitable.masks <- names(r) %>%
    set_names() %>%
    purrr::map(function(name) {
      unique.vals <- unique(values.at.presences[[name]])
      if (length(unique.vals) == 2) {
        # Binary method
        mode.val <- as.numeric(names(sort(table(values.at.presences[[name]]), 
                                          decreasing = T)[1]))
        return(r[[name]] == mode.val)
      } else {
        # 10th and 90th percentile method
        lower.bound <- quantile(values.at.presences[[name]], 0.1, na.rm = T)
        upper.bound <- quantile(values.at.presences[[name]], 0.9, na.rm = T)
        return((r[[name]] >= lower.bound) & (r[[name]] <= upper.bound))
      }
    }) %>% rast()
  
  # Combine individual masks to get areas that have the highest suitablity
  sum(suitable.masks)
}

bioclim.list <- purrr::map(1:nrow(spec.state), function(i) {
  st=spec.state[i,]$state
  spec=spec.state[i,]$species
  sf.subset <- sf::st_as_sf(df[state == st & common.name==spec], 
                            crs=4326, sf_column_name = "geometry")
  suitable.areas <- bioclim.suitability(sf.subset, r.list[[st]])
  list(
    bioclim=suitable.areas,
    state=st,
    species=spec,
    df=sf.subset
  )
})


# Example
plot(purrr::detect(bioclim.list, ~.x$state == "OR" & 
             .x$species == "Sanderling")$bioclim, 
     main = "BIOCLIM Suitability for Sanderlings in Oregon")
```

```{r bioclim-ex-2}
# Example
qnt.25 <- quantile(values(purrr::detect(bioclim.list, ~.x$state == "OR" & 
                         .x$species == "Sanderling")$bioclim), .25, na.rm=T)
plot(purrr::detect(bioclim.list, ~.x$state == "OR" & 
             .x$species == "Sanderling")$bioclim < qnt.25, 
     main = "BIOCLIM Suitable sample regions for Sanderlings in Oregon")
```


```{r mask-rasters, results="hide"}

# Load 5k resolution mask rasters
mask.dir <- "artifacts/masks_5k"
masks <- states %>%
  set_names() %>%
  purrr::map(function(st) {
    species %>%
      set_names() %>%
      purrr::map(function(spec) {
        fname <- file.path(mask.dir, paste0(st, "_", spec, ".tif"))
        rast(fname)
    }) %>% rast()
  })

# Load the original sample regions for pseudo-absence points
pa.regions.dir <- "artifacts/pseudo_absence_regions"
pa.regions <- states %>%
  set_names() %>%
  purrr::map(function(st) {
    species %>%
      set_names(species) %>%
      purrr::map(function(spec) {
        fname <- file.path(
          pa.regions.dir,
          gsub(" |\\-", "_", paste0(paste(st, tolower(spec), sep="_"), ".tif"))
        )
        rast(fname)
      }) %>%
      rast()
  })

purrr::walk(1:nrow(spec.state), function(i) {
  st <- spec.state[i,]$state
  spec <- spec.state[i,]$species
  msk <- masks[[st]][[spec]]
  pa.region <- pa.regions[[st]][[spec]]
  idx <- purrr::detect_index(bioclim.list, ~.x$state == st & 
                        .x$species == spec)
  bioclim.list[[idx]]$mask <<- msk
  bioclim.list[[idx]]$pseudo.absence.region <<- pa.region
  qnt.25 <- quantile(values(bioclim.list[[idx]]$bioclim), .25, na.rm=T)
  bioclim.list[[idx]]$qnt.25 <<- qnt.25
  bioclim.list[[idx]]$final.pseudo.absence.region <<-
    bioclim.list[[idx]]$bioclim <= qnt.25 & pa.region == 1
})
   

plot(purrr::detect(bioclim.list, ~.x$state == "OR" & 
             .x$species == "Sanderling")$final.pseudo.absence.region, 
     main = "Final Suitable sample regions for Sanderlings in Oregon") 

```

### Sampling Pseudo-Absences and Comparing Totals

This section identifies areas outside the buffers as potential zones for pseudo-absences. To ensure an accurate representation, a random sampling mechanism is implemented. For each bird species in a state, an equivalent number of pseudo-absence points (or a pre-defined minimum threshold), based on observed data are generated. The result is a set of coordinates representing regions where the bird species have not been observed. 

```{r select-pa, results="hide"}

# Function to sample n points from the non-masked parts
sample.inverse.mask <- function(r.final, n, 
                                spec, st,
                                sample.crs=4326, 
                                min.n=500,
                                resamples=100) {
  
  # Convert the raster to SpatialPoints
  gdf <- terra::as.points(r.final) %>%
    st_as_sf() %>%
    st_transform(crs=sample.crs)
  if (nrow(gdf) > 0) {
    gdf <- gdf %>%
      filter(!is.na(layer)) %>%
      select(geometry)
  } else {
    return(gdf)
  }
  
  # Set to min.n size if n < min.n
  if (n < min.n) n <- min.n
  # Make sure there is sufficient available sample points
  if (n > nrow(gdf)) n <- nrow(gdf)
  
  # Resample multiple times
  resampled.data <- lapply(1:resamples, function(i) {
    sample.idx <- sample(1:nrow(gdf), n)
    samples <- gdf[sample.idx,] %>%
      mutate(common.name = spec, 
             state = st, 
             lon = NA, 
             lat = NA,
             observations=0)
    
    # Populate lon and lat values:
    coords <- st_coordinates(samples)
    samples$lon <- coords[, "X"]
    samples$lat <- coords[, "Y"]
    
    list(sample.indices = sample.idx, samples = samples)
  })
  
  # Separate the sample indices and samples into two lists
  sample.indices.list <- lapply(resampled.data, `[[`, "sample.indices")
  samples.list <- lapply(resampled.data, `[[`, "samples")
  
  list(sample.indices = sample.indices.list, 
       samples = samples.list)
}

# Get totals by species and state
totals <- df[, .(.N), by=.(state, common.name)]
n.resamples <- 100

resampled.pa <- states %>%
  set_names() %>%
  purrr::map(function(st) {
    species %>%
      set_names() %>%
      purrr::map(function(spec) {
        n <- totals[state == st & common.name == spec] %>% pull(N)
        get.object({
          idx <- purrr::detect_index(bioclim.list, ~.x$state == st & 
                                       .x$species == spec)
          r.final <- bioclim.list[[idx]]$final.pseudo.absence.region
          cat(idx, "- Generating ~", n, "pseudo-absence points resampled",
              n.resamples, "times for the", spec, "in", st, "\n")
          sample.inverse.mask(
            r.final, spec, st, n=n, 
            sample.crs=4326, 
            resamples=n.resamples)
        },
        paste0(st, "_", spec, "_", n, "_", n.resamples, ".rds"),
        "artifacts/resampled_pseudo_absences_with_bioclim")
      })
  })

```


```{r get-rast-vals, results='hide'}

dfs <- states %>%
  set_names() %>%
  purrr::map(function(st) {
    r <- r.list[[st]]
    species %>%
      set_names() %>%
      purrr::map(function(spec) {
        cat("Getting values for", spec, "in", st, "\n")
        get.object({
          sf.pres <- sf::st_as_sf(
            df[state == st & common.name==spec, 
               .(geometry, common.name, state)], 
            crs=4326, sf_column_name = "geometry")
          # Extract values from rasters at presence locations
          pres.vals <- sf.pres %>%
            cbind(terra::extract(r, st_transform(sf.pres, crs=crs(r)))) %>%
            select(-ID) %>%
            st_transform(crs(sf.pres)) %>%
            filter(dplyr::if_all(names(.), ~!is.na(.))) %>%
            suppressWarnings()
          abs.vals <- resampled.pa[[st]][[spec]]$samples %>%
            purrr::map(~{
              .x %>%
                cbind(terra::extract(r, st_transform(.x, crs=crs(r)))) %>%
                select(-ID) %>%
                st_transform(crs(sf.pres)) %>%
                filter(dplyr::if_all(names(.), ~!is.na(.))) %>%
                suppressWarnings()
            })
          list(
            presence=pres.vals,
            pseudo.absence=abs.vals
          )
        },
        paste0(spec, "_", st, ".rds"),
        "artifacts/resampled_pa_with_bioclim_values")
      })
  })
```

```{r compare-tots}

# Compare the total number of values in each dataset (just spot-checking here)
purrr::map_df(1:nrow(spec.state), function(i) {
  spec <- spec.state[i,]$species
  st <- spec.state[i,]$state
  d <- dfs[[st]][[spec]]
  prs <- nrow(d$presence)
  p.abs <- purrr::map_dbl(d$pseudo.absence, ~nrow(.x))
  min.p.abs <- min(p.abs)
  max.p.abs <- max(p.abs)
  tibble(
    state=st,
    species=spec,
    presence=prs,
    min.pseudo.abs=min.p.abs,
    max.pseudo.abs=max.p.abs
  )
})

```

### Identify "Redundant" Rasters

As previously stated, many of the features are redundant. In particular, the "engineered" features were meant to improve upon the original features, and reduce multi-collinearity. Based on the original results of the feature selection process, it was shown that the new variables weren't always necessarily "better". Below is the list of raster layers that were determined should be removed from each of the rasters in order to minimize multi-collinearity and maximize model performance. 

```{r remove-redundant-features}

# Define "redundant" rasters/features
redund.feat <- c("open_water", "developed_open_space", "developed_low_intensity",
                 "developed_medium_intensity", "developed_high_intensity", "hay_pasture",
                 "cultivated_crops", "wetlands", "forest", "lon.lat.interaction", 
                 "waterbody", "urban_imperviousness", "tmax", "tmin", "dem", "Fall_NDVI",
                 "Spring_NDVI", "Summer_NDVI", "Winter_NDVI", "lat.sqrd", "lon.sqrd")

```

### Re-Fit LASSO Models with All Features

As was done in part 2, a GLM model is fit for each of the species/state subsets using the training data, but this time with the refined raster subset.

```{r glm-feature-selection}

# Load variable importance from fitted LASSO models
lasso.model.path="artifacts/models/lasso_3_fs"
train.samples <- floor(.75 * length(dfs[[st]][[spec]]$pseudo.absence))
test.samples <- length(dfs[[st]][[spec]]$pseudo.absence) - train.samples

species %>% 
  purrr::walk(function(spec) {
    states %>% 
      purrr::walk(function(st) {
        # Define the control for the train function
        ctrl <- trainControl(method = "cv", number = 5)
        
        cat("Fitting LASSO model for", spec, "in", st, "\n")
        spec.df <- dfs[[st]][[spec]]$presence[train.test$index,] %>%
          setDT()
        spec.df <- spec.df[
          common.name == spec & state == st][
            , `:=` (state=NULL, common.name = NULL, geometry=NULL, 
                    presence=factor(T, levels=c("TRUE", "FALSE")))]
        
        # Remove any columns where all values are the same
        .remove <- c(names(which(sapply(spec.df, function(x) {
          length(unique(x)) <= 1}))),
          redund.feat, "lat", "lon", "observations") %>% 
          unique()
        .remove <- .remove[.remove %in% names(spec.df)]
        .remove <- .remove[.remove != "presence"]
        if (!is_empty(.remove)) {
          spec.df <- spec.df %>% dplyr::select(-.remove)
        }
        # The last iteration will be saved as a test set
        purrr::walk(
          1:train.samples, function(i) {
            fname <- paste0(tolower(gsub(" ", "_", spec)), "_", st,
                            "_", i, "_regr_l1.rds")
            if (!file.exists(fname)) {
              if (i == 1) gc()
              cat("Fitting LASSO model for", i, "/", train.samples,
                  "iterations, for", spec, "observations in", st, "\n")
              abs.df <- dfs[[st]][[spec]]$pseudo.absence[[i]] %>% setDT()
              abs.df <- abs.df[
                common.name == spec & state == st][
                  , `:=` (state=NULL, common.name = NULL, geometry=NULL, 
                          presence=factor(F, levels=c("TRUE", "FALSE")))]
              if (!is_empty(.remove)) {
                abs.df <- abs.df %>% dplyr::select(names(spec.df))
              }
              train.df <- data.table::rbindlist(list(spec.df, abs.df))
              
              # LASSO (L1); Elastic Net, where alpha = 1
              fit <- get.object(
                train(presence ~ (.)^2, 
                      data = train.df, 
                      method = "glmnet",
                      family = "binomial",
                      trControl = ctrl,
                      tuneGrid = expand.grid(alpha = 1, 
                                             lambda = seq(0, 1, by = 0.1)),
                      metric = "Accuracy"),
                file.name=fname,
                obj.path=lasso.model.path)
              coef.df <- coef(fit$finalModel, s = fit$bestTune$lambda) %>%
                as.matrix() %>%
                as.data.frame()
              # Remove the intercept
              coef.df <- coef.df[-1, , drop = F]
              if (sum(coef.df$s1, na.rm=T) == 0) {
                # Remove file
                file.remove(file.path(lasso.model.path, fname))
                # Re-train model, this time with variable alpha in 
                # the train grid
                fit <- get.object(
                  train(presence ~ (.)^2, 
                        data = train.df, 
                        method = "glmnet",
                        family = "binomial",
                        trControl = ctrl,
                        tuneGrid = expand.grid(
                          alpha = seq(0, 1, by = 0.1), 
                          lambda = seq(0, 1, by = 0.1)),
                        metric = "Accuracy"),
                  file.name=fname,
                  obj.path=lasso.model.path)
                coef.df <- coef(fit$finalModel, s = fit$bestTune$lambda) %>%
                  as.matrix() %>%
                  as.data.frame()
                # Remove the intercept
                coef.df <- coef.df[-1, , drop = F]
                if (sum(coef.df$s1, na.rm=T) == 0) {
                  file.remove(file.path(lasso.model.path, fname))
                  cat("\tERROR: Try another method for obtaining coefs for",
                      spec, "in", st, "\n")
                }
              }
            }
          })
      })
  })
    
```
    
```{r get-top-vars}
    
# Define min/max scaling function for rasters
min.max.scale <- function(x, na.rm=T) {
  min.x <- min(x, na.rm=na.rm)
  max.x <- max(x, na.rm=na.rm)
  (x - min.x) / (max.x - min.x)
}

get.var.imp <- function(st, spec, dir="artifacts/models/lasso_3_fs") {
  files <- list.files(dir) %>%
    .[grepl(paste(tolower(gsub(" ", "_", spec)), st, sep="_"), .)] %>%
    file.path(dir, .)
  if (length(files) == 0) return(
    tibble(
      common.name=character(0),
      state=character(0),
      variable=character(0),
      importance=numeric(0),
      wt=numeric(0),
      weighted.imp=numeric(0)
    )
  )
  var.imp <- purrr::map_df(files, ~{
    fit <- readRDS(.x)
    coef.df <- coef(fit$finalModel, s = fit$bestTune$lambda) %>%
      as.matrix() %>%
      as.data.frame()
    # Remove the intercept
    coef.df <- coef.df[-1, , drop = F]
    # Create a data frame of variable importance
    var.importance <- tibble(
      common.name = spec,
      state = st,
      variable = rownames(coef.df),
      importance = abs(coef.df[,1])
    ) %>%
      # Rank variables by importance
      arrange(state, common.name, -importance, variable) %>%
      # Only look at variables where imp. > 0
      filter(importance > 0)
  }) %>%
    mutate(n=n()) %>%
    group_by(common.name, state, variable, n, .drop=F) %>%
    summarize(importance=median(importance), 
              wt=n()) %>%
    ungroup() %>%
    mutate(wt=wt/n) %>%
    select(-n) %>%
    mutate(weighted.imp=min.max.scale(wt*importance)) %>%
    arrange(-weighted.imp, variable) 
}

var.imp <- purrr::map_df(1:nrow(spec.state), function(i) {
  spec <- spec.state[i,]$species
  st <- spec.state[i,]$state
  get.var.imp(st, spec)
})

var.imp

```

```{r pa-prob}

get.pa.prob <- function(st, spec, dfs,
                        dir="artifacts/models/lasso_3_fs", 
                        train.samples=75,
                        test.samples=25,
                        verbose=F) {
  files <- list.files(dir) %>%
    .[grepl(paste(tolower(gsub(" ", "_", spec)), st, sep="_"), .)] %>%
    file.path(dir, .)
  if (length(files) == 0) return(NULL)
  
  # Get columns that should be removed (based on original presence data)
  spec.df <- dfs[[st]][[spec]]$presence[train.test$index,] %>%
    setDT()
  spec.df <- spec.df[
    common.name == spec & state == st][
      , `:=` (state=NULL, common.name = NULL, geometry=NULL, 
              presence=factor(T, levels=c("TRUE", "FALSE")))]
  .remove <- c(names(which(sapply(spec.df, function(x) {
    length(unique(x)) <= 1}))),
    redund.feat, "lat", "lon", "observations") %>% 
    unique()
  .remove <- .remove[.remove %in% names(spec.df)]
  .remove <- .remove[.remove != "presence"]
  tot <- length(dfs[[st]][[spec]]$pseudo.absence)
  preds <- purrr::map(1:tot, function(i) {
    .train <- ifelse(i <= train.samples, T, F) 
    abs.df <- dfs[[st]][[spec]]$pseudo.absence[[i]] %>%
      setDT() %>%
      .[common.name == spec & state == st] %>%
      .[, `:=` (state=NULL, common.name = NULL, 
                geometry=sf::st_as_text(geometry),
                presence=factor(F, levels=c("TRUE", "FALSE")))]
    geom <- abs.df$geometry
    abs.df[, geometry := NULL]
    if (!is_empty(.remove)) {
      abs.df <- abs.df %>% dplyr::select(-.remove)
    }
    preds.j <- files[1:train.samples] %>%
      purrr::imap(function(f, j) {
        if (verbose) cat(i, "/", tot, "Getting predictions for model", j, 
                         "for", spec, "in", st, "\n")
        get.object({
          fit <- readRDS(f)
          yhat <- predict(fit, newdata=abs.df, type="prob") %>%
            setDT() %>%
            .[, .(`FALSE`)] %>%
            setnames("FALSE", paste0("abs.prob.", j))},
          paste0(st, "_", spec, "_", i, "_", j, ".rds"),
          "artifacts/pa_probs")
      }) %>% do.call("cbind", .)
    
    preds.j[, `:=` (med=apply(.SD, 1, median), 
                    id=.I, sample=i, train=.train,
                    geometry=geom, state=st,
                    common.name=spec)] %>% 
      setorderv(x=., cols="med", order=-1)
    preds.j[, .(state, common.name, id, sample, med, train, geometry)]
  }) %>% rbindlist()
}

purrr::walk(1:nrow(spec.state), function(i) {
  spec <- spec.state[i,]$species
  st <- spec.state[i,]$state
  cat(spec, st, "\n")
  tryCatch({get.object(
    {get.pa.prob(st, spec, dfs, 
                 train.samples=train.samples, 
                 test.samples=test.samples,
                 verbose=F) %>% 
        setorderv(c("train", "med"), order=c(-1, -1))},
    paste0(st, "_", spec, ".rds"),
    "artifacts/pa_prob_results"
  )}, error=function(e) NULL)
})

```


```{r}

purrr::walk(1:nrow(spec.state), function(i) {
  spec <- spec.state[i,]$species
  st <- spec.state[i,]$state
  f <- file.path("artifacts/pa_prob_results", paste0(st, "_", spec, ".rds"))
  if (file.exists(f)) {
    get.object({
      dt <- readRDS(f)
      ntrain <- train.test$train[common.name==spec & state==st] %>% nrow()
      ntest <- train.test$test[common.name==spec & state==st] %>% nrow()
      cat(spec, st, ntrain, ntest, "\n")
      trn <- dt[train==T][1:ntrain] %>% 
        sf::st_as_sf(x=., crs=4326, wkt="geometry")
      tst <- dt[train==F][1:ntest] %>% 
        sf::st_as_sf(x=., crs=4326, wkt="geometry")
      list(train=trn, test=tst)
    }, paste0(st, "_", spec, ".rds"),
    "artifacts/train_test_pseudo_abs_updated")
  }
})

```
