---
title: 'SDM Benchmark Study Part 9: Fitting and Testing Common ML Models'
author: "Benton Tripp"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: flatly
    df_print: paged
  
---

<style>
.tocify-extend-page {
  height: 0 !important;
}
.post_navi {
  display: flex
}

.post_navi-label {
  font-size: 0.8em;
  opacity: 0.5
}

.post_navi .post_navi-item {
  padding: 0 2.2em;
  width: 50%;
  position: relative;
  color: inherit !important
}

.post_navi .nav_prev {
  text-align: left
}

.post_navi .nav_next {
  text-align: right
}

.post_navi .nav_prev .post_navi-arrow {
  left: 0
}

.post_navi .nav_next .post_navi-arrow {
  right: 0
}

.post_navi .post_navi-arrow {
  position: absolute;
  top: 50%;
  transform: translateY(-50%);
  font-size: 2.5em;
  opacity: 0.3
}

footer .wrapper {
  max-width: -webkit-calc(800px - (30px*2));
  max-width: calc(800px - (30px*2));
  margin-right: auto;
  margin-left: auto;
  padding-right: 30px;
  padding-left: 30px
}

@media screen and (max-width:800px) {
  footer .wrapper {
    max-width: -webkit-calc(800px - (30px));
    max-width: calc(800px - (30px));
    padding-right: 15px;
    padding-left: 15px
  }
}

footer .wrapper:after,
.footer-col-wrapper:after {
  content: "";
  display: table;
  clear: both
}

.svg-icon {
  width: 26px;
  height: 16px;
  display: inline-block;
  fill: #828282;
  padding-right: 5px;
  vertical-align: text-top
}

.social-media-list li+li {
  padding-top: 5px
}

.site-footer {
  border-top: 1px solid #e8e8e8;
  padding: 30px 0
}

.footer-heading {
  font-size: 18px;
  margin-bottom: 15px
}

.contact-list,
.social-media-list {
  list-style: none;
  margin-left: 0;
  width: 155px;
}

.footer-col-wrapper {
  font-size: 15px;
  color: #828282;
  margin-left: -15px
}

.footer-col {
  float: left;
  margin-bottom: 15px;
  padding-left: 15px
}

.footer-col-1 {
  width: 30%;
}

.footer-col-2 {
  width: 25%;
}

.footer-col-3 {
  width: 45%;
}

@media screen and (max-width:800px) {

  .footer-col-1,
  .footer-col-2 {
    width: -webkit-calc(50% - (30px/2));
    width: calc(50% - (30px/2))
  }

  .footer-col-3 {
    width: -webkit-calc(100% - (30px/2));
    width: calc(100% - (30px/2))
  }
}

@media screen and (max-width:600px) {
  .footer-col {
    float: none;
    width: -webkit-calc(100% - (30px/2));
    width: calc(100% - (30px/2))
  }
}
</style>

```{r setup, include=F, warning=F, message=F}
knitr::opts_chunk$set(echo = T, message=F, warning=F, cache=F, root.dir="..")
```

## Overview

## Setup

```{r setup-2, results='hide'}

# Load libraries
library(sf)
library(terra)
library(ggplot2)
library(ggpubr)
library(dplyr)
library(readr)
library(data.table)
library(knitr)
library(purrr)
library(caret)

# Set seed 
set.seed(19)

# Load pre-processed data
source("R/load_preprocessed_data.R")
# Load other utility function
source("R/get_objects.R")
# Load Variable Importance
source("R/load_variable_importance.R")
# Load model accuracy function
source("R/model_accuracy.R")

```

```{r setup-3}

# Get data into normal data frame format (not `spatstat`)
data <- states %>%
  set_names() %>%
  purrr::map(function(st) {
  # Get raster by state
  r <- rasters[[st]]
  species %>% 
    set_names() %>%
    purrr::map(function(spec) {
      # Load `spatstat` quad data
      Q <- readRDS(file.path("artifacts", "train_spatstat_Q_2",
                             paste0(st, "_", spec, "_Q.rds")))
      Q.test <- readRDS(file.path("artifacts", "test_spatstat_Q_2",
                                  paste0(st, "_", spec, "_Q.rds")))
      # Load presence/absence data
      pres.train <- data.table(
        x=Q$data$x, 
        y=Q$data$y,
        presence=factor(T, levels=c(F,T), 
                        labels=c("Absence", "Presence")))
      abs.train <- data.table(
        x=Q$dummy$x, 
        y=Q$dummy$y, 
        presence=factor(F, levels=c(F,T),
                        labels=c("Absence", "Presence")))
      pres.test <- data.table(
        x=Q.test$data$x, 
        y=Q.test$data$y,
        presence=factor(T, levels=c(F,T),
                        labels=c("Absence", "Presence")))
      abs.test <- data.table(
        x=Q.test$dummy$x, 
        y=Q.test$dummy$y,
        presence=factor(F, levels=c(F,T),
                        labels=c("Absence", "Presence")))
      purrr::walk(names(r), function(n) {
        pres.train[, (n) := terra::extract(r[[n]], 
                                           cbind(pres.train$x,
                                                 pres.train$y))]
        abs.train[, (n) := terra::extract(r[[n]], 
                                          cbind(abs.train$x,
                                                abs.train$y))]
        pres.test[, (n) := terra::extract(r[[n]], 
                                          cbind(pres.test$x,
                                                pres.test$y))]
        abs.test[, (n) := terra::extract(r[[n]], 
                                         cbind(abs.test$x,
                                               abs.test$y))]
      })
      list(
        train=data.table::rbindlist(l=list(pres.train, abs.train)) %>%
          na.omit(),
        test=data.table::rbindlist(l=list(pres.test, abs.test)) %>%
          na.omit()
      )
    })
  })

```

## ML Models

```{r ml-setup, results='hide'}

control <- trainControl(method="cv", 
                        number=5, 
                        classProbs = T)

train.test <- function(model.type, fname, spec.state, data, var.imp.data, 
                       control, tune.grid=NULL, cov.keep=50) {
  purrr::walk(1:nrow(spec.state), function(i) {
    spec <- spec.state[i, ]$species
    st <- spec.state[i, ]$state
    fit.path <- file.path(paste0("artifacts/models/", fname),
                          paste0(spec, "_", st, "_", fname, ".rds"))
    results.path <- file.path(paste0("artifacts/test_results/", fname),
                              paste0(spec, "_", st, "_", fname, ".rds"))
    if (!file.exists(results.path)) {
      d <- data[[st]][[spec]]$train
      features <- var.imp.data[[st]][[spec]]
      cov.kepp <- covariates.keep
      spec.sens.check <- F
      while (!spec.sens.check) {
        # Create formula
        feats <- features$variable[1:covariates.keep] %>%
          purrr::keep(~!is.na(.x))
        covariates.keep <- length(feats)
        # Create formula
        .f <- feats %>%
          paste(., collapse=" + ") %>% 
          paste("presence ~", .) %>% 
          as.formula()
        # Generalized for different model types
        if (model.type == "logistic regression") {
          fit <- train(.f, data = d, 
                       method = "glm", 
                       family = "binomial",
                       trControl = control, 
                       metric = "Accuracy")
        } else if (model.type %in% c("tree", "knn", "random forest", "xgboost")) {
          .method <- case_when(model.type == "tree" ~ "rpart",
                               model.type %in% c("knn") ~ model.type,
                               model.type == "random forest" ~ "ranger",
                               model.type == "xgboost" ~ "xgbTree"
                               T ~ "tree")
          fit <- train(.f, data=d, 
                 method = .method,
                 trControl = control, 
                 tuneGrid = tune.grid,
                 metric = "Accuracy")
        } else {
          stop("Invalid model type")
        }
        # Cache model object
        get.object(
          obj=fit,
          file.name=paste0(spec, "_", st, "_", fname, ".rds"), 
          obj.path=paste0("artifacts/models/", fname)) %>%
          suppressWarnings()
        
        pred <- predict(fit, d, type="prob")$Presence
        train.results <- cbind(
          d, data.table(obs = ifelse(d$presence == "Presence", T, F),
                        p.obs = pred))
        optimal.threshold <- optimize.f1(train.results)
        cm <- get.acc(train.results, optimal.threshold)
        acc <- tibble(
          common.name=spec,
          state=st,
          covariate.count=covariates.keep,
          optimal.threshold=optimal.threshold 
        ) %>%
          cbind(as.list(c(cm$overall, cm$byClass)) %>% 
                  as_tibble()) %>%
          select(common.name:Accuracy, Sensitivity, Specificity, F1)
        cat("Train Results:\n Species:", spec, "\n",
            "State:", st, "\n",
            "Covariates:", covariates.keep, "\n",
            "Optimal Threshold:", optimal.threshold, "\n",
            "Accuracy:", acc$Accuracy, "\n",
            "F1:", acc$F1, "\n",
            "Sensitivity (TP Rate):", acc$Sensitivity, "\n",
            "Specificity (TN Rate):", acc$Specificity, "\n")
        if ((acc$Sensitivity == 1 & acc$Specificity == 0) | 
            (acc$Sensitivity == 0 & acc$Specificity == 1)) {
          cat("\tThe sensitivity/specificity is a 0/1 pair",
              "for covariates.keep ==", covariates.keep, "\n")
          spec.sens.check <- F
          file.remove(glm.path)
          covariates.keep <- covariates.keep - 1
          if (covariates.keep < 1) {
            stop("\tUnable to successfully fit a model given the data.\n")
          } 
          next
        } else {
          spec.sens.check <- T
        }
      }
      
      results <- get.object(
        {
          d.test <- data[[st]][[spec]]$test
          pred.test <- predict(fit, d.test, type="prob")
          test.results <- cbind(d.test, 
                                data.table(obs = ifelse(
                                  d.test$presence == "Presence", T, F),
                                  p.obs = pred.test$Presence))
          cm <- get.acc(test.results, optimal.threshold)
          test.acc <- tibble(
            common.name=spec,
            state=st,
            covariate.count=covariates.keep,
            optimal.threshold=optimal.threshold 
          ) %>%
            cbind(as.list(c(cm$overall, cm$byClass)) %>% 
                    as_tibble()) %>%
            select(common.name:Accuracy, Sensitivity, Specificity, F1)
          all.predictions <- rasters[[st]] %>% 
            as.data.table() %>%
            predict(fit, ., type="prob") %>%
            .$Presence
          list(
            test=test.results,
            train=train.results,
            all.preds=all.predictions,
            thresh=optimal.threshold,
            train.accuracy=acc,
            test.accuracy=test.acc
          )
        },
        file.name=paste0(spec, "_", st, "_", fname, ".rds"),
        obj.path=paste0("artifacts/test_results/", fname)
      )
      cat("\tFinished model for", spec, "in", st, "\n")
    }
  })
}

```

### Logistic Regression

```{r train-lr, results='hide'}

train.test(model.type="logistic regression", 
           fname="logreg", 
           spec.state, 
           data, 
           var.imp.data,
           control, 
           cov.keep=50)

```

### Classification Tree

```{r train-dt, results='hide'}

train.test(model.type="tree", 
           fname="tree", 
           spec.state, 
           data, 
           var.imp.data,
           control, 
           tune.grid=data.frame(cp=seq(0, 0.1, by = 0.01)),
           cov.keep=50)

```

### K-Nearest Neighbors

```{r train-knn, results='hide'}

train.test(model.type="knn", 
           fname="knn", 
           spec.state, 
           data, 
           var.imp.data,
           control, 
           tune.grid=data.frame(k=1:10),
           cov.keep=50)

```

### Random Forest

```{r train-rf, results='hide'}

train.test(model.type="random forest", 
           fname="randomforest", 
           spec.state, 
           data, 
           var.imp.data,
           control, 
           tune.grid=expand.grid(
             splitrule=c("extratrees", "gini"),
             mtry=c(1,5,10),
             min.node.size=c(1,5,10)
           ),
           cov.keep=50)

```

### XGBoost

```{r train-xgb, results='hide'}

train.test(model.type="xgboost", 
           fname="xgboost", 
           spec.state, 
           data, 
           var.imp.data,
           control, 
           tune.grid=expand.grid(
             nrounds = c(100, 300),
             eta = c(0.01, 0.1),
             max_depth = c(3, 6, 9),
             colsample_bytree = c(0.5, 1),
             min_child_weight = c(1, 5),
             subsample = c(0.5, 1)
           ),
           cov.keep=50)

```

### Results



